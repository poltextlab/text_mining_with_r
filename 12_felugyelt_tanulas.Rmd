# Osztályozás és felügyelt tanulás

## Fogalmi alapok

```{r, include=FALSE}

source("_common.R")

```

A mesterséges intelligencia két fontos társadalomtudományi alkalmazási területe a felügyelet nélküli és a felügyelt tanulás. Míg az előző esetben -- ahogy azt a *[Felügyelet nélküli tanulás: topik modellezés magyar törvényszövegeken](#lda_ch)* fejezetben bemutattuk -- az emberi beavatkozás néhány kulcsparaméter megadására (így pl. a kívánt topikok számának meghatározására) szorítkozik, addig a felügyelt tanulás esetében a kutatónak nagyobb mozgástere van "tanítani" a gépet. Ennyiben a felügyelt tanulás alkalmasabb hipotézisek tesztelésére, mint az adatok rejtett mintázatait felfedező felügyelet nélküli tanulás. 

A felügyelt tanulási feladat megoldása egy úgynevezett tanító halmaz (*training set*) meghatározásával kezdődik, melynek során a kutatók saját maguk végzik el kézzel azt a feladatot melyet a továbbiakban gépi közreműködéssel szeretnének nagyobb nagyságrendben, de egyben érvényesen (*validity*) és megbízhatóan (*reliability*) kivitelezni. Eredményeinket az ugyanúgy eredetileg kézzel lekódolt, de a modell-építés során félretett teszthalmazunkon (*test set*) értékelhetjük. Ennek során négy kategóriába rendezzük modellünk előrejelzéseit. Egy, a politikusi beszédeket a pozitív hangulatuk alapján osztályozó példát véve ezek a következők: azok a beszédek amelyeket a modell helyesen sorolt be pozitívba (valódi pozitív), vagy negatívba (valódi negatív), illetve azok, amelyek hibásan szerepelnek a pozitív (ál-pozitív), vagy a negatív kategóriában (ál-negatív). Mindezek együttesen egy ún. tévesztési táblát (*confusion matrix*) adnak, melynek további elemzésével ítéletet alkothatunk modellépítésünk eredményességéről.

A felügyelt tanulás számos kutatási feladat megoldására alkalmazhatjuk, melyek közül a leggyakoribbak a különböző osztályozási (classification) feladatok. Miközben ezek – így pl. a véleményelemzés – szótáralapú módszertannal is megoldhatóak (lásd a *[Szótáralapú elemzések, érzelem-elemzés](#sentiment)* fejezetet), a felügyelt tanulás a nagyobb élőmunkaigényt rendszerint jobb eredményekkel és rugalmasabb felhasználhatósággal hálálja meg (gondoljunk csak a szótárak domain-függőségére). A felügyelt tanulás egyben a mesterséges intelligencia kutatásának gyorsan fejlődő területe, mely az e fejezetben tárgyalt algoritmus-központú gépi tanuláson túl az ún. mélytanulás (*deep learning*) és a neurális hálók területén is zajlik egyre látványosabb sikerekkel.


## Osztályozás felügyelt tanulással

Az alábbi fejezetben a CAP magyar média gyűjteményéből a napilap címlapokat tartalmazó modult használjuk.[^sml-1] Az induló adatbázis 61 835 cikk szövegét és metaadatait (összesen öt változót: sorszám, fájlnév, a közpolitikai osztály kódja, szöveg, illetve a korpusz forrása -- *Magyar Nemzet* vagy *Népszabadság*) tartalmazza. Az a célunk, hogy az egyes cikkekhez kézzel, jó minőségben (két, egymástól függetlenül dolgozó kódoló által) kiosztott és egyeztetett közpolitikai kódokat -- ez a tanítóhalmaz -- arra használjuk, hogy meghatározzuk egy kiválasztott cikkcsoport hasonló kódjait. Az osztályozási feladathoz a CAP közpolitikai kódrendszerét használjuk, mely 21 közpolitikai kategóriát határoz meg az oktatástól az egészségügyön át a honvédelemig. [^sml-2]

[^sml-1]: A korpusz regisztációt követően elérhető az alábbi linken: <https://cap.tk.hu/a-media-es-a-kozvelemeny-napirendje>

[^sml-2]: A kódkönyv regisztrációt követően elérhető az alábbi linken: [https://cap.tk.hu/kozpolitikai-cap](https://cap.tk.hu/kozpolitikai-cap)

Annak érdekében, hogy egyértelműen értékelhessük a gépi tanulás hatékonyságát, a kiválasztott cikkcsoport (azaz a teszthalmaz) esetében is ismerjük a kézi kódolás eredményét („éles“ kutatási helyzetben, ismeretlen kódok esetében ugyanakkor ezt gyakran szintén csak egy kisebb mintán tudjuk kézzel validálni). További fontos lépés, hogy az észszerű futási idő érdekében a gyakorlat során a teljes adatbázisból -- és ezen belül is csak a Népszabadság részhalmazból -- fogunk venni egy 4500 darabos mintát. E mintán fogjuk vizsgálni, hogy milyen hatékonysággal képes a modellünk egy megadott közpolitikai kódba besorolni egy adott cikket, illetve, hogy ezt képes-e a hús-vér kutatókkal azonos színvonalon megtenni. Nézzük mindezek után a kutatás lépéseit!

A először behívjuk a szükséges csomagokat, melyek közül a `quanteda` a szokásos szövegbányászati alapcsomagunk, az `e1071` az SVM algoritmus használatát teszi a lehetővé, a `ggplot2` a vizualizációt segíti, a `dplyr` a korpuszon végzett műveletekhez kell, a `SparseM` pedig a mátrixtranszformációkhoz.

```{r include = TRUE}
library(quanteda)
library(e1071)
library(ggplot2)
library(dplyr)
library(SparseM)
library(HunMineR)

set.seed(1234)
```

Ezt követően megadjuk azt a kódkategóriát, melynek kapcsán szeretnénk elvégezni a bináris osztályozást (beletartozik-e az adott cikk az adott kategóriába vagy nem). A kódban ez az egyes, azaz a makrogazdaság (adózás, költségvetés, monetáris politika stb.) lesz.

```{r include = TRUE}
CAPcode <- 1
```

Ezt követi a szövegelőkészítésen és tisztításon már átesett adatok betöltése. Az egyszerűség kedvéért a `HunMineR` csomagból töltjük be az előkészített adatokat.

```{r include = TRUE}
Data_NOL_MNO <- HunMineR::data_nol_mno_clean
```

A következő lépésben eltávolítjuk a szöveges adatot nem tartalmazó (a text változóra semmilyen értéket nem adó) sorokat az adatbázisból.

```{r include = TRUE}
Data_NOL_MNO_ures <- Data_NOL_MNO[Data_NOL_MNO$text == "",]
Data_NOL_MNO <- Data_NOL_MNO[!(Data_NOL_MNO$filename %in% Data_NOL_MNO_ures$filename),]
```

```{r include = TRUE}
nrow(Data_NOL_MNO_ures)
```

Látható, hogy összesen 13 ilyen elemet találtunk.

Majd szétválasztjuk a két újsághoz tartozó cikkeket is (esetünkben a *Népszabadságot* alapul véve).

```{r include = TRUE}
Data_NOL <- Data_NOL_MNO[Data_NOL_MNO$corpus == "NOL",]
```

Mint az *Environment* ablakban is látható, ez a lépés `r nrow(Data_NOL)` cikkes halmazt adott. Ezen a ponton megkezdhetjük a felügyelt gépi tanulásra épülő lépéseket! Először egy 4500-as mintát veszünk az adatbázisból, hogy rövidítsük a futásidőt.

```{r include = TRUE}
Data_NOL <- Data_NOL[sample(nrow(Data_NOL), 4500), ]
```


Majd kutatási feladatunknak megfelelően felveszünk egy új címkét (*label*), ami már kifejezetten azt mutatja, hogy egy cikk a makrogazdasági (1) vagy bármilyen más (0) osztályba tartozik-e.

```{r include = TRUE}
Data_NOL$label <- ifelse(Data_NOL$majortopic_code == CAPcode, 1, 0)
```

Ezt követően felosztjuk a 4500 cikket 2:1 arányban tanító- és teszthalmazra.

```{r}
training <- Data_NOL[sample(nrow(Data_NOL), 3000), ]
Data_NOL$training <- ifelse(Data_NOL$filename %in% training$filename, 1, 0)
```


Ahhoz, hogy a `quanteda` dtm-et tudjon készíteni a cikk-gyűjteményünkből, először egy korpusz objektumot kell létrehozni belőlük.

```{r include = TRUE}
lemma_corpus_NOL <- corpus(Data_NOL, docid_field = "filename", text_field = "text")
```

Így a dfm függvénnyel már létre tudjuk hozni a dokumentum-kifejezés mátrixunkat!

```{r include = TRUE}
dtm_NOL <- lemma_corpus_NOL %>% 
  tokens() %>% 
  dfm()
```

A dimenzió-csökkentés érdekében eltávolítjuk a ritka (5-nél kevesebbszer szereplő) kifejezéseket a mátrixból. Láthatjuk, hogy ezzel a feature -ök majd 81 százalékát eltávolítottuk.



```{r, message=TRUE}
dtm_NOL <- dfm_trim(dtm_NOL, min_docfreq = 5, verbose=TRUE)
```

Ezen a ponton megkezdhetjük a modellünk tanítását! Erre a fent említett SVM algoritmust használjuk. E lépés futási ideje akár 1--2 percig is eltarthat.

```{r eval=FALSE}
SVMmodel <- svm(
  x=dtm_NOL[dtm_NOL@docvars$training == 1,], 
  y	=dtm_NOL[dtm_NOL@docvars$training == 1,]@docvars$label,
  kernel="linear", 
  cost	=0.1, 
  probability=TRUE
  )
```

```{r echo=FALSE}
#saveRDS(SVMmodel, file = "data/temp/svm_model.rds")
SVMmodel <- readRDS("data/temp/svm_model.rds")
```

A létrejövő *predictions* objektum tartalmazza majd az előrejelzési eredményeket.

```{r include = TRUE}
predictions <- predict(SVMmodel, dtm_NOL[dtm_NOL@docvars$training == 0,])
```

```{r include = TRUE}
Data_NOL_predictions <- cbind(Data_NOL[Data_NOL$training == 0,], predictions)
```

Ezt követően meghatározzuk azt a küszöbértéket, ahonnan egy előrejelzést 1-es címkéhez tartozónak (azaz egy cikk szövegét makrogazdaságinak) tekintünk.

```{r include = TRUE}
cutoff_point = 0.5
```

Majd ez alapján átalakítjuk az SVM eredményeinket immár a végleges, a bináris osztályozási feladatnak megfelelő előrejelzésekké. A `cbind` függvénnyel pedig összevonjuk egy táblázatba az előrejelzés eredményét és annak cimkéit.

```{r include = TRUE}
predictions_label <- ifelse(predictions > 0.5, 1, 0)
```

```{r include = TRUE}
Data_NOL_predictions <- cbind(Data_NOL_predictions, predictions_label)
```

Miután eredményeink elkészültek, kiszámoljuk a felügyelt gépi tanulás szokásos eredményességi mutatóit (ettől a résztől kódunkban Pablo Barbera munkájára támaszkodunk)[^sml3]. Mindezek alapjául a tévesztési mátrix szolgál, először ennek adatait vizsgáljuk meg.

[^sml3]: Elérhető az alábbi linken: [http://pablobarbera.com/ECPR-SC105/code/12-advanced-sml.html](http://pablobarbera.com/ECPR-SC105/code/12-advanced-sml.html).

```{r include = TRUE}
conf_mat <- table(Data_NOL_predictions$predictions_label, Data_NOL_predictions$label)

conf_mat
```

Látható, hogy modellünk alapvetően helyesen értékelte, hogy a teszthalmaz cikkeinek döntő többsége nem makrogazdasági tárgyú (`r conf_mat[1]`). Szintén sikerrel sorolt be `r conf_mat[4]` cikket a makrogazdasági osztályba. Ugyanakkor `r conf_mat[3]`-et hibásan tartott 1-es kategóriásnak, `r conf_mat[2]`-t pedig nem „talált meg” közülük.

A mutatószámok esetében kezdjük a legáltalánosabbal, a hitelességgel (*accuracy*), ami a mátrix átlójára épít.

```{r include = TRUE}
accuracy <- function(ypred, y){
  tab <- table(ypred, y)
  return(sum(diag(tab))/sum(tab))
}

```

```{r include = TRUE}
accuracy(Data_NOL_predictions$predictions_label, Data_NOL_predictions$label)
```

Ennek adatai azt mutatják, hogy nagy általánosságban jól működött a modell. Ugyanakkor kutatási kérdésünk szempontjából fontosabb, hogy milyen arányban találtuk meg a makrogazdasági cikkeket (felidézés -- *recall*), illetve milyen pontossággal osztottuk ki ezeket a kódokat (pontosság -- *precision*). A következő lépésben így először definiáljuk, majd kiszámoljuk a pontosságot és a felidézést, valamint ezek harmonikus átlagát, az F1 mutatót.

```{r include = TRUE}
precision <- function(ypred, y){
  tab <- table(ypred, y)
  return((tab[2,2])/(tab[2,1]+tab[2,2]))
}
```

```{r include = TRUE}
recall <- function(ypred, y){
  tab <- table(ypred, y)
  return(tab[2,2]/(tab[1,2]+tab[2,2]))
}
```

```{r include = TRUE}
F1 <- function(ypred, y){
  return(2*precision(ypred, y)*recall(ypred, y)/(precision(ypred, y)+recall(ypred, y)))
}
```

```{r include = TRUE}
precision(Data_NOL_predictions$predictions_label, Data_NOL_predictions$label)

recall(Data_NOL_predictions$predictions_label, Data_NOL_predictions$label)

F1(Data_NOL_predictions$predictions_label, Data_NOL_predictions$label)
```

Összességében azt állapíthatjuk meg, hogy „játékmodellünk” közel hasonló arányú, azaz 60 százalékos pontosságot, illetve fedést eredményezett. Ez elmaradt a kettős vak kézi kódolás akár 80-90 százalékos találati arányától, ugyanakkor mintánkat didaktikai okokból szándékosan kisebbre vettük a lehetségesnél. A nagymintás adatok alapján (lásd @sebokMulticlassClassificationNewspaper2021) különösen a pontosság esetében akár 90 százalék feletti érték is elérhető felügyelt gépi tanulással, mely ponton már világossá válik a mesterséges intelligenciára épülő megközelítés versenyképessége a kézi kódoláséval, különösen nagymintás projektek esetében.

De térjünk még vissza eredményeinkhez és vizsgáljuk meg őket közpolitikai kódonként is! Itt is látható, hogy `r table(Data_NOL_predictions$predictions_label, Data_NOL_predictions$majortopic_code)[2]` cikkre jeleztük előre helyesen az 1-es kódot.

```{r include = TRUE}
table(Data_NOL_predictions$predictions_label, Data_NOL_predictions$majortopic_code)
```

Végezetül előrejelzéseinket ezek kódonkénti gyakorisága szempontjából ábrázoljuk.

```{r include = TRUE}
ggplot_data <- Data_NOL_predictions[,c("majortopic_code","predictions_label")]
ggplot_data$predictions_label <- factor(ggplot_data$predictions_label)
```

```{r include = TRUE}
df <- ggplot_data %>%
  group_by(majortopic_code, predictions_label) %>%
  summarise(n = n()) %>% 
  filter(majortopic_code < 30)
```

```{r include = TRUE, fig.cap="Az SVM modell klasszifikációs eredményei"}
ggplot(df, aes(majortopic_code, n, fill = predictions_label)) + 
  geom_bar(stat = "identity") +
  labs(fill = NULL) +
  theme(legend.position = "bottom")
```
